# Pedagogical Contract for Self-Directed Web Sustainability MOOC

## Purpose
This document defines the learning agreement between the platform and the learner. It establishes how learning happens, how it is measured, and what constitutes success in a self-directed, privacy-first environment.

## Learning Principles

1.  **Role-Specific Relevance**: Content is filtered strictly by ARRM roles (UX Designer, Visual Designer, Content Author, Front-end Developer). Learners only engage with decisions they have the power to influence.
2.  **Action Over Theory**: Every learning unit must result in a concrete, measurable change to a real-world web artifact. Theory serves only to justify the action.
3.  **The Pedagogical Loop**: Mastery is strictly defined by the execution of the cycle: **Learn** (context) → **Do** (intervention) → **Measure** (impact) → **Reflect** (internalization).
4.  **Evidence-Based Progress**: Progress is tracked by the generation of proofs (screenshots, reports, code diffs, file size reductions), not by passive consumption of video or text.
5.  **Privacy-Preserving Autonomy**: The learner owns their learning data. There are no accounts, no tracking pixels, and no backend evaluations. Assessment is local and self-verified.
6.  **Sustainability as Quality**: Sustainable web practices are taught not as ethical add-ons, but as core indicators of professional craft and product quality (performance, accessibility, usability).
7.  **Cumulative Impact**: Individual lesson outputs are designed to accumulate into a comprehensive "Sustainability Impact Report" for a specific project.
8.  **Source-Truth Alignment**: All instructions are traceable to Web Sustainability Guidelines (WSG) consistency, but interpreted for practical decision-making.

## Allowed Assessment Types

These assessments focus on application, analysis, and evaluation.

*   **Diagnostic Audits**: Running specific tools (e.g., Lighthouse, EcoGrader, image analysis) to establish baselines and verify improvements.
*   **Before/After Comparisons**: Documenting the state of an artifact (code block, image, user flow) before and typically after an intervention.
*   **Calculated Impact**: Estimating data transfer reduction (KB/MB) or carbon avoidance based on specific changes.
*   **Decision Logs**: Documenting the trade-off made during a design or technical choice (e.g., "Chose system font over custom font to save 400KB").
*   **Reflective Checklists**: Validating work against a heuristic list after the work is done.
*   **Portfolio Artifacts**: Saving a simplified version of a complex asset (e.g., a compressed SVG, a rewritten plain-language policy).

## Disallowed Assessment Types

These assessments focus on recall, memorization, or require external validation, which violates the contract.

*   **Recall-based Multiple Choice**: "What does WSG 2.1 say about X?" (Testing memory of text is banned).
*   **True/False Fact Checks**: "The internet emits 4% of global carbon." (Trivia is not a skill).
*   **Theoretical Essays**: Writing about why sustainability is important without doing it.
*   **Peer Review**: Cannot be supported without accounts and privacy tradeoffs.
*   **Proctored Exams**: Incompatible with the trust model and self-directed nature.
*   **Automated Code Grading**: Requires backend execution environments which introduces security and privacy complexity.

## Definition of "Completion"

### Per Lesson
A lesson is considered **complete** only when the learner has successfully navigated the full loop:
1.  **Context**: Read the requirement and identified where it applies in their work.
2.  **Action**: Performed the specific optimization or design change on a local asset.
3.  **Measurement**: Recorded the "After" metric (e.g., new file size, new accessibility score) to prove to themselves that the action had an effect.
4.  **Reflection**: Written a brief local note on the friction encountered or the value gained.

### Per Track (Role)
A Role Track is considered **complete** when the learner has:
1.  Systematically completed all required Action Loops for that role.
2.  Generated a cumulative **Impact Report** containing the aggregate evidence (saved bytes, improved scores, design decisions) from the lessons.
3.  Self-certified that the evidence provided is their own work and reflects an honest effort to apply the principles.
